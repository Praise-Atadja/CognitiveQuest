# -*- coding: utf-8 -*-
"""model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LAaQu7puNB-fvb1h1zCm2tcjflDW1tAO

# **PROJECT NAME: CognitiveQuest**
---
(***This project is to predict the possibility of autism***)

# **CASE STUDY IMPLEMENTATION**

**Abstract**:
Autistic Spectrum Disorder (ASD) is a neurodevelopmental condition associated with significant healthcare costs, and early diagnosis can significantly reduce these. Unfortunately, waiting times for an ASD diagnosis are lengthy and procedures are not cost effective.

**Objective:**

Creating a Multi-layer Perceptron(MLP) model offline and saving it as a pkl file.

Evaluate the model(s) using all the metrics required on a Jupyter Notebook and demonstrate how good is the model(s)

1. Create the whole pipeline process with Python functions.
2. Load the pipeline on the cloud platform in such a way that the model can be retrained again, and create a trigger for retraining the model when the need arises.
3. Demonstrate the evaluation process of the model in production.
4. [Optional] Simulate a flood of requests(using software like Locust) send them to the model and show how the model responds to these requests. Record and show the latency and response time of the requests with different numbers of docker containers.
5. Demonstrate how a user uploads values/features and the model predicts

# **MODEL FUNCTION**
"""

#Import Necessary Libraries
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import classification_report
import joblib
from joblib import dump
from google.colab import drive
drive.mount('/content/drive')
import os
import xgboost as xgb
import pickle
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, roc_auc_score, cohen_kappa_score, confusion_matrix
from xgboost import XGBClassifier
from sklearn.ensemble import AdaBoostClassifier
import preprocessing.py

"""1. Random Forest Classifier"""

def train_random_forest(X_train, X_test, y_train, y_test, tune=False):
    if tune:
        # Define the parameter grid
        param_grid = {
            'n_estimators': [100, 200, 300],
            'max_features': ['sqrt'],
            'max_depth': [None, 10, 20, 30],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4],
            'criterion': ['entropy']
        }
        # Initialize the Random Forest model
        model = RandomForestClassifier(random_state=50)
        # Apply GridSearchCV
        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, verbose=1, scoring='accuracy')
        grid_search.fit(X_train, y_train)
        # Best parameters found
        best_params = grid_search.best_params_
        print(f"Best parameters with hyperparameter tuning: {best_params}")
        # Initialize model with best parameters
        model = RandomForestClassifier(**best_params)
    else:
        # Initialize model with default parameters
        model = RandomForestClassifier()

    # Train the model
    model.fit(X_train, y_train)

    # Predictions
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probability estimates of the positive class (for log loss and AUC)

    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    logloss = log_loss(y_test, y_pred_proba)
    auc = roc_auc_score(y_test, y_pred_proba)
    kappa = cohen_kappa_score(y_test, y_pred)
    error_rate = 1 - accuracy

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)

    # Output the results
    if tune:
        print("Random Forest - Training Results with hyperparameter tuning:")
    else:
        print("Random Forest - Training Results without hyperparameter tuning:")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"Log Loss: {logloss:.4f}")
    print(f"AUC Score: {auc:.4f}")
    print(f"Kappa Score: {kappa:.4f}")
    print(f"Error Rate: {error_rate:.4f}")
    print(f"Confusion Matrix:\n{cm}\n")

    # Save the model
    model_path = "/content/models/random_forest.pkl"
    joblib.dump(model, model_path)
    print(f"Trained model saved as {model_path}")

    return model


train_random_forest(X_train, X_test, y_train, y_test, tune=True)
train_random_forest(X_train, X_test, y_train, y_test, tune=False)

"""AdaBoost Classifier"""

def train_adaboost(X_train, X_test, y_train, y_test, tune=False):
    if tune:
        # Define the parameter grid
        param_grid = {
            'n_estimators': [50, 100, 200],
            'learning_rate': [0.1, 0.5, 1.0]
        }
        # Initialize the AdaBoost model
        model = AdaBoostClassifier(random_state=0)
        # Apply GridSearchCV
        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, verbose=1, scoring='accuracy')
        grid_search.fit(X_train, y_train)
        # Best parameters found
        best_params = grid_search.best_params_
        print(f"Best parameters with hyperparameter tuning: {best_params}")
        # Initialize model with best parameters
        model = AdaBoostClassifier(**best_params, random_state=0)
    else:
        # Initialize model with default parameters
        model = AdaBoostClassifier(random_state=0)

    # Train the model
    model.fit(X_train, y_train)

    # Predictions
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probability estimates of the positive class (for log loss and AUC)

    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    logloss = log_loss(y_test, y_pred_proba)
    auc = roc_auc_score(y_test, y_pred_proba)
    kappa = cohen_kappa_score(y_test, y_pred)
    error_rate = 1 - accuracy

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)

    # Output the results
    if tune:
        print("AdaBoost - Training Results with hyperparameter tuning:")
    else:
        print("AdaBoost - Training Results without hyperparameter tuning:")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"Log Loss: {logloss:.4f}")
    print(f"AUC Score: {auc:.4f}")
    print(f"Kappa Score: {kappa:.4f}")
    print(f"Error Rate: {error_rate:.4f}")
    print(f"Confusion Matrix:\n{cm}\n")

    # Save the model
    model_dir = "/content/models"
    if not os.path.exists(model_dir):
        os.makedirs(model_dir)
    model_path = os.path.join(model_dir, "ada_boost.pkl")
    joblib.dump(model, model_path)
    print(f"Trained model saved as {model_path}")

    return model


train_adaboost(X_train, X_test, y_train, y_test, tune=True)
train_adaboost(X_train, X_test, y_train, y_test, tune=False)

"""XGBoost Classifier"""

def train_xgboost(X_train, X_test, y_train, y_test, tune=False):
    if tune:
        # Define the parameter grid for hyperparameter tuning
        param_grid = {
              'n_estimators': [100],
              'max_depth': [3],
              'learning_rate': [0.01],
              'min_child_weight': [1],
              'gamma': [0],
              'subsample': [0.6],
              'colsample_bytree': [0.6],
              'reg_alpha': [0],
              'reg_lambda': [0]
        }
        # Initialize the XGBoost model
        model = XGBClassifier(random_state=42)
        # Apply GridSearchCV for hyperparameter tuning
        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, verbose=1, scoring='accuracy')
        grid_search.fit(X_train, y_train)
        # Best parameters found
        best_params = grid_search.best_params_
        print(f"Best parameters with hyperparameter tuning: {best_params}")
        # Initialize model with best parameters
        model = XGBClassifier(**best_params)
    else:
        # Initialize model with default parameters
        model = XGBClassifier(random_state=42)

    # Train the model
    model.fit(X_train, y_train)

    # Predictions
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probability estimates of the positive class (for log loss and AUC)

    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    logloss = log_loss(y_test, y_pred_proba)
    auc = roc_auc_score(y_test, y_pred_proba)
    kappa = cohen_kappa_score(y_test, y_pred)
    error_rate = 1 - accuracy

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)

    # Output the results
    if tune:
        print("XGBoost - Training Results with hyperparameter tuning:")
    else:
        print("XGBoost - Training Results without hyperparameter tuning:")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"Log Loss: {logloss:.4f}")
    print(f"AUC Score: {auc:.4f}")
    print(f"Kappa Score: {kappa:.4f}")
    print(f"Error Rate: {error_rate:.4f}")
    print(f"Confusion Matrix:\n{cm}\n")

    return model


train_xgboost(X_train, X_test, y_train, y_test, tune=True)
train_xgboost(X_train, X_test, y_train, y_test, tune=False)

# Saving the trained model
model = train_xgboost(X_train, X_test, y_train, y_test, tune=True)  # Example: Training with hyperparameter tuning
with open('/content/models/xgboost.pkl', 'wb') as file:
    pickle.dump(model, file)

"""Selecting the best Model"""

def select_best_model(model_accuracies):
    """
    Selects the model with the highest accuracy from a dictionary of model accuracies.

    """
    # Select the model with the highest accuracy
    best_model_name = max(model_accuracies, key=model_accuracies.get)
    best_model_accuracy = model_accuracies[best_model_name]

    return best_model_name, best_model_accuracy


model_accuracies = {
    'Random Forest': 1.0,
    'Support Vector Classifier':1.0,
    'XGBoost Classifier': 1.0
}

best_model_name, best_model_accuracy = select_best_model(model_accuracies)
print(f"Best model: {best_model_name}, Accuracy: {best_model_accuracy}")

# scaling function
def min_max_scale_numerical_features(features, features_numerical):
    scaler = MinMaxScaler()
    features_minmax_transform = pd.DataFrame(data=features)
    features_minmax_transform[features_numerical] = scaler.fit_transform(features[features_numerical])
    return features_minmax_transform

# encoding function
def encode_categorical_columns(features_minmax_transform):
    le = LabelEncoder()
    for column in features_minmax_transform.columns:
        if pd.api.types.is_numeric_dtype(features_minmax_transform[column]):
            continue
        features_minmax_transform[column] = le.fit_transform(features_minmax_transform[column])
    return features_minmax_transform

# Preprocess features function
def preprocess_features(input_data):
    features_numerical = ['age']  # Define numerical features
    input_data_scaled = min_max_scale_numerical_features(input_data, features_numerical)
    input_data_encoded = encode_categorical_columns(input_data_scaled)
    return input_data_encoded

# Load the Random Forest model from the pickle file
random_forest_model = joblib.load("/content/models/random_forest.pkl")

# Prediction function
def predict_input(random_forest_model):
    # Collect user input
    print("Please enter the following information:")
    A1_Score = int(input("A1 Score (0/1): "))
    A2_Score = int(input("A2 Score (0/1): "))
    A3_Score = int(input("A3 Score (0/1): "))
    A4_Score = int(input("A4 Score (0/1): "))
    A5_Score = int(input("A5 Score (0/1): "))
    A6_Score = int(input("A6 Score (0/1): "))
    A7_Score = int(input("A7 Score (0/1): "))
    A8_Score = int(input("A8 Score (0/1): "))
    A9_Score = int(input("A9 Score (0/1): "))
    A10_Score = int(input("A10 Score (0/1): "))
    age = int(input("Age: "))
    gender = input("Gender (Male/Female): ")
    ethnicity = input("Ethnicity: ")
    jaundice = input("Jaundice history (Yes/No): ")
    autism = input("Autism diagnosis (Yes/No): ")
    country_of_res = input("Country of residence: ")
    used_app_before = input("Used app before (Yes/No): ")
    relation = input("Relation (Health care professional/Others/Parent/Relative/Self): ")
    age_range = input("Age range (4-8/9-13/14-18/19-23/24-28/29-33/34-38/39-43/44-48/49-53/54-58/59-63): ")

    # Create a DataFrame from the user input
    input_data = pd.DataFrame({
        'A1_Score': [A1_Score],
        'A2_Score': [A2_Score],
        'A3_Score': [A3_Score],
        'A4_Score': [A4_Score],
        'A5_Score': [A5_Score],
        'A6_Score': [A6_Score],
        'A7_Score': [A7_Score],
        'A8_Score': [A8_Score],
        'A9_Score': [A9_Score],
        'A10_Score': [A10_Score],
        'age': [age],
        'gender': [gender],
        'ethnicity': [ethnicity],
        'jaundice': [jaundice],
        'autism': [autism],
        'country_of_res': [country_of_res],
        'used_app_before': [used_app_before],
        'relation': [relation],
        'age_range': [age_range]
    })


    # Preprocess the input data
    input_data_transformed = preprocess_features(input_data)

    # Make prediction
    prediction = model.predict(input_data_transformed)

    # Output the prediction
    print("Prediction: ", "Yes, ASD" if prediction == 1 else "No ASD")


predict_input(random_forest_model)