{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praise-Atadja/CognitiveQuest/blob/main/Transfer_Learning_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ULN_4YKurPH"
      },
      "source": [
        "# **PROJECT NAME: CognitiveQuest**\n",
        "---\n",
        "(***This project is to predict the possibility of autism***)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qHAn-zOvXLl"
      },
      "source": [
        "# **OBJECTIVE**\n",
        "\n",
        "This project aims to use transfer learning techniques to predict Autism Spectrum Disorder (ASD) from image data. This involves fine-tuning pre-trained neural network models on a dataset related to ASD. The steps include preprocessing the images, selecting a suitable pre-trained model, adjusting its parameters, and evaluating its performance using accuracy, precision, recall, and F1-score metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utN9QnjMvuw1"
      },
      "source": [
        "## **The Dataset**\n",
        "\n",
        "\n",
        "**Short Description of the Data:**\n",
        "\n",
        "This dataset consists of images categorized into two classes: \"autistic\" and \"non_autistic\", aiming to facilitate research and analysis in understanding autism spectrum traits. The dataset is divided into three main folders: \"train\", \"valid\", and \"test\", each containing two subfolders representing the two classes.\n",
        "\n",
        "**Folder Structure:**\n",
        "\n",
        "train: Contains 1263 images in each of the \"autistic\" and \"non_autistic\" subfolders, totaling 2526 images.\n",
        "\n",
        "valid: Contains 100 images in each of the \"autistic\" and \"non_autistic\" subfolders, totaling 200 images.\n",
        "\n",
        "test: Contains 100 images in each of the \"autistic\" and \"non_autistic\" subfolders, totaling 200 images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as0oPIlPxRrj",
        "outputId": "bd7e40a2-dd54-488f-8e88-ff792b76e452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Import Necessary Libraries\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGFWvBw0wooY"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jBtq0rldqkR",
        "outputId": "f7f027e4-afdb-4854-bb9f-c157adfc63b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2575 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# dataset directories\n",
        "train_dir = \"/content/drive/MyDrive/dataset/train\"\n",
        "valid_dir = \"/content/drive/MyDrive/dataset/valid\"\n",
        "test_dir = \"/content/drive/MyDrive/dataset/test\"\n",
        "\n",
        "def load_data(train_dir, valid_dir, test_dir, img_height=224, img_width=224, batch_size=32):\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    valid_generator = valid_datagen.flow_from_directory(\n",
        "        valid_dir,\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    return train_generator, valid_generator, test_generator\n",
        "\n",
        "train_generator, valid_generator, test_generator = load_data(train_dir, valid_dir, test_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "F9-jf2biBdI7"
      },
      "outputs": [],
      "source": [
        "#Base Model\n",
        "\n",
        "def build_model(base_model, num_classes=2):\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "def train_model(model, train_generator, valid_generator, epochs=10):\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(train_generator, validation_data=valid_generator, epochs=epochs)\n",
        "    return history\n",
        "\n",
        "def evaluate_model(model, test_generator):\n",
        "    y_true = test_generator.classes\n",
        "    y_pred = model.predict(test_generator)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "    loss = model.evaluate(test_generator)[0]\n",
        "    precision = precision_score(y_true, y_pred_classes)\n",
        "    recall = recall_score(y_true, y_pred_classes)\n",
        "    f1 = f1_score(y_true, y_pred_classes)\n",
        "\n",
        "    return accuracy, loss, precision, recall, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D3Vuf6UbHbG"
      },
      "source": [
        "##Loading Pre-trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Byph46g6XDJ_"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained models\n",
        "vgg_base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "resnet_base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "inception_base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOyLwr_bgGEx"
      },
      "source": [
        "# Fine-tuning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "n5qwvO6yCfEJ"
      },
      "outputs": [],
      "source": [
        "# Unfreeze some top layers of the pre-trained models for fine-tuning\n",
        "for layer in vgg_base_model.layers[-4:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "for layer in resnet_base_model.layers[-10:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "for layer in inception_base_model.layers[-15:]:\n",
        "    layer.trainable = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "N9bFf4wOCh7W"
      },
      "outputs": [],
      "source": [
        "# Compile the models\n",
        "vgg_model = build_model(vgg_base_model)\n",
        "resnet_model = build_model(resnet_base_model)\n",
        "inception_model = build_model(inception_base_model)\n",
        "\n",
        "vgg_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "resnet_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "inception_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLgtMt4yCvqA",
        "outputId": "53482298-98a7-4a15-d2a0-92debc63be91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "81/81 [==============================] - 61s 705ms/step - loss: 2.8869 - accuracy: 0.5076 - val_loss: 0.6962 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "81/81 [==============================] - 56s 693ms/step - loss: 0.6937 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.4750\n",
            "Epoch 3/5\n",
            "81/81 [==============================] - 56s 688ms/step - loss: 0.6932 - accuracy: 0.5014 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "81/81 [==============================] - 55s 681ms/step - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "81/81 [==============================] - 56s 684ms/step - loss: 0.6931 - accuracy: 0.5056 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 1/5\n",
            "81/81 [==============================] - 87s 674ms/step - loss: 1.9673 - accuracy: 0.6035 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "81/81 [==============================] - 55s 674ms/step - loss: 0.6379 - accuracy: 0.6462 - val_loss: 0.8636 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "81/81 [==============================] - 54s 669ms/step - loss: 0.5668 - accuracy: 0.7243 - val_loss: 0.7510 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "81/81 [==============================] - 53s 654ms/step - loss: 0.5416 - accuracy: 0.7383 - val_loss: 4.1236 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "81/81 [==============================] - 55s 674ms/step - loss: 0.6138 - accuracy: 0.7417 - val_loss: 0.6864 - val_accuracy: 0.4950\n",
            "Epoch 1/5\n",
            "81/81 [==============================] - 81s 620ms/step - loss: 1.4406 - accuracy: 0.5045 - val_loss: 2.2573 - val_accuracy: 0.5200\n",
            "Epoch 2/5\n",
            "81/81 [==============================] - 51s 625ms/step - loss: 0.6970 - accuracy: 0.5045 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "81/81 [==============================] - 52s 634ms/step - loss: 0.6933 - accuracy: 0.4788 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "81/81 [==============================] - 50s 612ms/step - loss: 0.6934 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "81/81 [==============================] - 52s 643ms/step - loss: 0.6932 - accuracy: 0.5056 - val_loss: 0.6932 - val_accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "# Train the models\n",
        "vgg_finetune_history = train_model(vgg_model, train_generator, valid_generator, epochs=5)\n",
        "resnet_finetune_history = train_model(resnet_model, train_generator, valid_generator, epochs=5)\n",
        "inception_finetune_history = train_model(inception_model, train_generator, valid_generator, epochs=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3USl7F_ggvD7"
      },
      "source": [
        "# Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "v3R2OjQXg0lo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2d0a67-7456-4143-9ff8-c6883bb65590"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 81s 13s/step\n",
            "7/7 [==============================] - 1s 139ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "7/7 [==============================] - 2s 156ms/step\n",
            "7/7 [==============================] - 1s 175ms/step - loss: 0.8205 - accuracy: 0.5000\n",
            "7/7 [==============================] - 3s 177ms/step\n",
            "7/7 [==============================] - 1s 132ms/step - loss: 0.6709 - accuracy: 0.7600\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the fine-tuned models\n",
        "vgg_finetune_eval_metrics = evaluate_model(vgg_model, test_generator)\n",
        "resnet_finetune_eval_metrics = evaluate_model(resnet_model, test_generator)\n",
        "inception_finetune_eval_metrics = evaluate_model(inception_model, test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bjO-rVjWs4Qc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "693b7184-970c-4664-b647-d8f85198471a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics for Fine-tuned VGG16 Model:\n",
            "Accuracy: 0.5\n",
            "Loss: 0.6931895613670349\n",
            "Precision: 0.5\n",
            "Recall: 1.0\n",
            "F1 Score: 0.6666666666666666\n",
            "\n",
            "Evaluation Metrics for Fine-tuned ResNet50 Model:\n",
            "Accuracy: 0.5\n",
            "Loss: 0.6839388012886047\n",
            "Precision: 0.5\n",
            "Recall: 0.99\n",
            "F1 Score: 0.6644295302013423\n",
            "\n",
            "Evaluation Metrics for Fine-tuned InceptionV3 Model:\n",
            "Accuracy: 0.5\n",
            "Loss: 0.6931672096252441\n",
            "Precision: 0.5\n",
            "Recall: 1.0\n",
            "F1 Score: 0.6666666666666666\n"
          ]
        }
      ],
      "source": [
        "# Print evaluation metrics for tuned models\n",
        "print(\"Evaluation Metrics for Fine-tuned VGG16 Model:\")\n",
        "print(\"Accuracy:\", vgg_finetune_eval_metrics[0])\n",
        "print(\"Loss:\", vgg_finetune_eval_metrics[1])\n",
        "print(\"Precision:\", vgg_finetune_eval_metrics[2])\n",
        "print(\"Recall:\", vgg_finetune_eval_metrics[3])\n",
        "print(\"F1 Score:\", vgg_finetune_eval_metrics[4])\n",
        "print()\n",
        "\n",
        "print(\"Evaluation Metrics for Fine-tuned ResNet50 Model:\")\n",
        "print(\"Accuracy:\", resnet_finetune_eval_metrics[0])\n",
        "print(\"Loss:\", resnet_finetune_eval_metrics[1])\n",
        "print(\"Precision:\", resnet_finetune_eval_metrics[2])\n",
        "print(\"Recall:\", resnet_finetune_eval_metrics[3])\n",
        "print(\"F1 Score:\", resnet_finetune_eval_metrics[4])\n",
        "print()\n",
        "\n",
        "print(\"Evaluation Metrics for Fine-tuned InceptionV3 Model:\")\n",
        "print(\"Accuracy:\", inception_finetune_eval_metrics[0])\n",
        "print(\"Loss:\", inception_finetune_eval_metrics[1])\n",
        "print(\"Precision:\", inception_finetune_eval_metrics[2])\n",
        "print(\"Recall:\", inception_finetune_eval_metrics[3])\n",
        "print(\"F1 Score:\", inception_finetune_eval_metrics[4])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkELcTGewtx5TZ/z+RlGTL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}